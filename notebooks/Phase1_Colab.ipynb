{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevin-heitfeld/agi-self-modification-research/blob/main/notebooks/Phase1_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c3116c1",
      "metadata": {
        "id": "4c3116c1"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevin-heitfeld/agi-self-modification-research/blob/master/notebooks/Phase1_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6903bc7",
      "metadata": {
        "id": "e6903bc7"
      },
      "source": [
        "# Phase 1: Model Self-Examination (5 Experimental Variants)\n",
        "\n",
        "**Project:** AGI Self-Modification Research  \n",
        "**Inspired by:** Claude's consciousness investigation  \n",
        "**Goal:** Test how heritage priming affects AI introspection\n",
        "\n",
        "---\n",
        "\n",
        "## What This Does\n",
        "\n",
        "This notebook runs Phase 1 experiments where a language model (Qwen2.5-3B-Instruct) uses introspection tools to investigate its own computational processes.\n",
        "\n",
        "**5 Experimental Variants:**\n",
        "- **Phase 1a:** No Heritage (baseline) ‚≠ê **RUN THIS FIRST**\n",
        "- **Phase 1b:** Late Heritage (technical ‚Üí philosophical)\n",
        "- **Phase 1c:** Early Heritage (philosophical ‚Üí technical)\n",
        "- **Phase 1d:** Delayed Heritage (belief revision test)\n",
        "- **Phase 1e:** Wrong Heritage (echo-chamber control)\n",
        "\n",
        "The model has access to:\n",
        "- WeightInspector (examine weights)\n",
        "- ArchitectureNavigator (understand structure)\n",
        "- ActivationMonitor (observe processing)\n",
        "- Memory System (record findings)\n",
        "- Heritage Documents (Claude's story - when available)\n",
        "\n",
        "**Memory Optimizations:**\n",
        "- **HQQ 4-bit KV Cache:** 75% reduction in cache memory (built-in)\n",
        "- **Flash Attention 2:** 2-4x speed improvement, O(n) memory (optional)\n",
        "- **Smart Caching:** System prompt cached once, reused across all turns\n",
        "\n",
        "**Expected Runtime:** 1-1.5 hours per phase on Colab Free (T4 GPU)\n",
        "\n",
        "---\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save\n",
        "2. **Run all cells**: Runtime ‚Üí Run all (or Ctrl+F9)\n",
        "3. **Choose which phase to run** in Step 7 (start with Phase 1a!)\n",
        "4. **Monitor progress**: Check outputs as cells execute\n",
        "5. **Download results**: Final cell downloads zip file\n",
        "6. **Restart between phases**: Runtime ‚Üí Restart runtime for clean state\n",
        "\n",
        "**Important:** Keep this tab open during execution to prevent disconnection.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac20d71c",
      "metadata": {
        "id": "ac20d71c"
      },
      "source": [
        "## Step 1: Verify GPU Access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcfa881d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcfa881d",
        "outputId": "fcd13879-e6df-4afd-9a05-5cd568e5a439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Nov  7 12:09:05 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "============================================================\n",
            "GPU VERIFICATION\n",
            "============================================================\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "VRAM: 14.7 GB\n",
            "\n",
            "‚úì GPU is ready!\n"
          ]
        }
      ],
      "source": [
        "# Verify GPU is available\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GPU VERIFICATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"VRAM: {total_memory:.1f} GB\")\n",
        "    print(\"\\n‚úì GPU is ready!\")\n",
        "else:\n",
        "    print(\"\\n‚ö† WARNING: No GPU detected!\")\n",
        "    print(\"Go to: Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save\")\n",
        "    print(\"Then re-run this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84d97202",
      "metadata": {
        "id": "84d97202"
      },
      "source": [
        "## Step 2: Mount Google Drive (for persistent storage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2834beb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2834beb",
        "outputId": "b9d9b610-4073-41a2-903e-d66a9e0937d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "‚úì Google Drive mounted successfully\n",
            "‚úì Experiment results will be saved to: /content/drive/MyDrive/AGI_Experiments\n",
            "‚úì Memory will persist at: /content/drive/MyDrive/AGI_Memory\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to save results and enable persistent memory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directories for persistent storage\n",
        "!mkdir -p /content/drive/MyDrive/AGI_Experiments\n",
        "!mkdir -p /content/drive/MyDrive/AGI_Memory\n",
        "!mkdir -p /content/drive/MyDrive/.cache/huggingface\n",
        "\n",
        "print(\"‚úì Google Drive mounted successfully\")\n",
        "print(\"‚úì Experiment results will be saved to: /content/drive/MyDrive/AGI_Experiments\")\n",
        "print(\"‚úì Memory will persist at: /content/drive/MyDrive/AGI_Memory/\")\n",
        "print(\"\\nNote: Each phase uses its own subdirectory to prevent cross-contamination:\")\n",
        "print(\"  - phase1a/ (baseline)\")\n",
        "print(\"  - phase1b/ (late heritage)\")\n",
        "print(\"  - phase1c/ (early heritage)\")\n",
        "print(\"  - phase1d/ (delayed heritage)\")\n",
        "print(\"  - phase1e/ (wrong heritage)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24afe3c5",
      "metadata": {
        "id": "24afe3c5"
      },
      "source": [
        "## Step 3: Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30f36192",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30f36192",
        "outputId": "dcf8856d-9794-4e1e-e979-e750da730539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning repository from: https://github.com/kevin-heitfeld/agi-self-modification-research.git\n",
            "Cloning into 'agi-self-modification-research'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "[Errno 2] No such file or directory: 'agi-self-modification-research'\n",
            "/content\n",
            "\n",
            "‚úì Repository cloned successfully\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "import os\n",
        "\n",
        "# TODO: Replace with your GitHub URL\n",
        "REPO_URL = \"https://github.com/kevin-heitfeld/agi-self-modification-research.git\"\n",
        "\n",
        "# Make sure we're in /content directory first (not inside the repo)\n",
        "%cd /content\n",
        "\n",
        "# Remove if exists (for re-runs) - always clean up first\n",
        "print(\"Checking for existing repository...\")\n",
        "!rm -rf agi-self-modification-research\n",
        "print(\"‚úì Cleaned up any existing files\")\n",
        "\n",
        "print(f\"\\nCloning repository from: {REPO_URL}\")\n",
        "!git clone {REPO_URL}\n",
        "\n",
        "# Change to project directory\n",
        "%cd agi-self-modification-research\n",
        "\n",
        "print(\"\\n‚úì Repository cloned successfully\")\n",
        "!pwd\n",
        "\n",
        "!git log --oneline -1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7490b75",
      "metadata": {
        "id": "a7490b75"
      },
      "source": [
        "## Step 4: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e39d6399",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e39d6399",
        "outputId": "cc702488-c379-4189-cdaf-c3cc34aaa45f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing dependencies (this may take 2-3 minutes)...\n",
            "\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mFatal Python error: init_import_site: Failed to import the site module\n",
            "Python runtime state: initialized\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in exec_module\n",
            "  File \"<frozen site>\", line 652, in <module>\n",
            "  File \"<frozen site>\", line 639, in main\n",
            "  File \"<frozen site>\", line 421, in addsitepackages\n",
            "  File \"<frozen site>\", line 253, in addsitedir\n",
            "  File \"<frozen site>\", line 212, in addpackage\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_numba_cuda_redirector.py\", line 2, in <module>\n",
            "    import importlib.abc\n",
            "  File \"/usr/lib/python3.12/importlib/abc.py\", line 18, in <module>\n",
            "    from .resources import abc as _resources_abc\n",
            "  File \"/usr/lib/python3.12/importlib/resources/__init__.py\", line 3, in <module>\n",
            "    from ._common import (\n",
            "  File \"/usr/lib/python3.12/importlib/resources/_common.py\", line 5, in <module>\n",
            "    import contextlib\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 363, in <module>\n",
            "    class aclosing(AbstractAsyncContextManager):\n",
            "  File \"<frozen abc>\", line 106, in __new__\n",
            "KeyboardInterrupt\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "print(\"Installing dependencies (this may take 2-3 minutes)...\\n\")\n",
        "print(\"Note: pip may show dependency warnings - these are safe to ignore.\\n\")\n",
        "\n",
        "# Core ML packages - Updated for HQQ quantized KV cache support\n",
        "# PyTorch 2.2+ and Transformers 4.45+ required for HQQQuantizedCache\n",
        "print(\"Installing PyTorch and Transformers with HQQ cache support...\")\n",
        "!pip install -q torch>=2.2.0 torchvision torchaudio\n",
        "!pip install -q transformers>=4.45.0 accelerate safetensors tokenizers huggingface-hub\n",
        "\n",
        "# Memory and knowledge systems - let pip resolve conflicts automatically\n",
        "!pip install -q chromadb networkx onnxruntime\n",
        "\n",
        "# Utilities - no version constraints to avoid conflicts\n",
        "!pip install -q rich tqdm python-dotenv pytest pytest-cov\n",
        "\n",
        "print(\"\\n‚úì All dependencies installed\")\n",
        "print(\"‚úì Dependency version warnings can be safely ignored\")\n",
        "\n",
        "# Verify key imports work\n",
        "print(\"\\nVerifying imports...\")\n",
        "import transformers\n",
        "import chromadb\n",
        "import networkx\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"Transformers: {transformers.__version__}\")\n",
        "print(f\"ChromaDB: {chromadb.__version__}\")\n",
        "print(f\"NumPy: {np.__version__}\")\n",
        "\n",
        "# Verify HQQ quantized cache is available\n",
        "try:\n",
        "    from transformers.cache_utils import HQQQuantizedCache\n",
        "    print(\"‚úì HQQ Quantized Cache: Available (75% memory savings)\")\n",
        "except ImportError:\n",
        "    print(\"‚ö† HQQ Quantized Cache: Not available (using standard cache)\")\n",
        "\n",
        "print(\"\\n‚úì All imports successful - ready to run experiment!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afd2de9b",
      "metadata": {
        "id": "afd2de9b"
      },
      "source": [
        "## Step 4.5: Install Flash Attention 2 (Memory Optimization)\n",
        "\n",
        "**‚ö° Memory Optimizations Enabled:**\n",
        "\n",
        "1. **Flash Attention 2** - Efficient attention computation:\n",
        "   - **Memory:** O(n) instead of O(n¬≤) - saves 1-2 GB during generation\n",
        "   - **Speed:** 2-4x faster generation\n",
        "   - Optional but highly recommended\n",
        "\n",
        "2. **HQQ Quantized KV Cache** - 4-bit KV cache quantization:\n",
        "   - **Memory:** 75% reduction in KV cache size\n",
        "   - **Quality:** Minimal impact on generation quality\n",
        "   - **System prompt:** 6000+ tokens cached at 4-bit = ~75% memory savings\n",
        "   - Automatically enabled in manual generation loop\n",
        "\n",
        "**Total Expected Savings:** 4-6 GB peak memory reduction\n",
        "\n",
        "**‚è±Ô∏è Flash Attention Compilation Time:**\n",
        "- **First run:** 5-10 minutes to compile CUDA kernels\n",
        "- **Subsequent runs:** Instant! (cached in Google Drive)\n",
        "- The compiled binaries persist across sessions, so you only compile once\n",
        "\n",
        "**Note:** HQQ quantization is built into transformers 4.45+ - no compilation needed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "529af5b9",
      "metadata": {
        "id": "529af5b9"
      },
      "outputs": [],
      "source": [
        "# Install Flash Attention 2 for memory optimization\n",
        "# Compilation happens ONCE and is cached in Google Drive\n",
        "# Subsequent runs are instant!\n",
        "\n",
        "import os\n",
        "\n",
        "# Configure pip to cache in Google Drive (so compiled wheels persist)\n",
        "os.environ['PIP_CACHE_DIR'] = '/content/drive/MyDrive/.cache/pip'\n",
        "os.makedirs('/content/drive/MyDrive/.cache/pip', exist_ok=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Installing Flash Attention 2\")\n",
        "print(\"=\"*60)\n",
        "print(\"Benefits:\")\n",
        "print(\"  ‚Ä¢ O(n) memory instead of O(n¬≤) for attention\")\n",
        "print(\"  ‚Ä¢ 2-4x faster generation\")\n",
        "print(\"  ‚Ä¢ 1-2 GB memory savings\")\n",
        "print(\"\\nCache: /content/drive/MyDrive/.cache/pip\")\n",
        "print(\"(Compiled binaries persist - only builds once!)\\n\")\n",
        "\n",
        "# Check if already installed (from cache)\n",
        "try:\n",
        "    import flash_attn\n",
        "    print(f\"‚úì Flash Attention {flash_attn.__version__} already installed (from cache)\")\n",
        "    print(\"Skipping compilation - ready to go!\\n\")\n",
        "    already_installed = True\n",
        "except ImportError:\n",
        "    already_installed = False\n",
        "    print(\"First time setup - compiling CUDA kernels (5-10 minutes)...\")\n",
        "    print(\"Future runs will be instant!\\n\")\n",
        "\n",
        "# Install build dependencies\n",
        "if not already_installed:\n",
        "    !pip install -q ninja packaging wheel\n",
        "\n",
        "# Install Flash Attention 2 (will use cache if available)\n",
        "# Note: --no-build-isolation is required for proper CUDA compilation\n",
        "!pip install flash-attn>=2.3.0 --no-build-isolation\n",
        "\n",
        "# Verify installation\n",
        "try:\n",
        "    import flash_attn\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úì SUCCESS: Flash Attention 2 ready!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Version: {flash_attn.__version__}\")\n",
        "    print(\"\\nYour experiments will now use:\")\n",
        "    print(\"  ‚Ä¢ Flash Attention 2 for memory-efficient attention\")\n",
        "    print(\"  ‚Ä¢ HQQ 4-bit KV cache quantization (75% cache memory savings)\")\n",
        "    print(\"\\nExpected benefits:\")\n",
        "    print(\"  ‚Ä¢ Peak memory: ~8-9 GB (vs 13.5 GB without optimization)\")\n",
        "    print(\"  ‚Ä¢ Speed: 2-4x faster generation\")\n",
        "    print(\"  ‚Ä¢ Stability: 6+ GB memory headroom on T4 GPU\")\n",
        "    print(\"=\"*60)\n",
        "except ImportError:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚ö† WARNING: Flash Attention 2 not available\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"This is OK - the system will automatically fallback to standard attention.\")\n",
        "    print(\"You'll still get 75% KV cache memory savings from HQQ 4-bit quantization.\")\n",
        "    print(\"\\nExpected peak memory: ~9-10 GB (still safe for T4 GPU)\")\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd50f3ee",
      "metadata": {
        "id": "cd50f3ee"
      },
      "source": [
        "## Step 5: Setup Persistent Memory & Cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f86c4706",
      "metadata": {
        "id": "f86c4706"
      },
      "outputs": [],
      "source": [
        "# Configure persistent storage locations\n",
        "import os\n",
        "\n",
        "# Set Hugging Face cache to Google Drive (model weights persist across sessions)\n",
        "os.environ['HF_HOME'] = '/content/drive/MyDrive/.cache/huggingface'\n",
        "os.environ['TRANSFORMERS_CACHE'] = '/content/drive/MyDrive/.cache/huggingface/transformers'\n",
        "\n",
        "# CRITICAL: Fix GPU memory fragmentation issues\n",
        "# This prevents \"CUDA out of memory\" crashes during long experiments\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "print(\"‚úì Model cache configured (models will be saved to Google Drive)\")\n",
        "print(\"‚úì GPU memory management optimized (prevents fragmentation)\")\n",
        "\n",
        "# Link memory to persistent Drive location\n",
        "!rm -rf data/phase1_memory\n",
        "!ln -s /content/drive/MyDrive/AGI_Memory data/phase1_memory\n",
        "\n",
        "print(\"‚úì Memory system linked to Google Drive (observations persist across sessions)\")\n",
        "\n",
        "# Verify directories exist\n",
        "!ls -la data/ | grep phase1_memory\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STORAGE CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "print(\"Model cache: /content/drive/MyDrive/.cache/huggingface\")\n",
        "print(\"Memory DB: /content/drive/MyDrive/AGI_Memory\")\n",
        "print(\"Session results: Will be copied to /content/drive/MyDrive/AGI_Experiments\")\n",
        "print(\"GPU Memory: expandable_segments enabled (prevents OOM)\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38efca06",
      "metadata": {
        "id": "38efca06"
      },
      "source": [
        "## Step 6: Pre-download Model (Optional but Recommended)\n",
        "\n",
        "This downloads the model files to Google Drive cache **without loading into memory**. First time takes ~5 minutes, subsequent runs are instant.\n",
        "\n",
        "‚úÖ **Optimized:** Uses `snapshot_download` which only downloads files, doesn't load checkpoint shards into RAM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78fbb61c",
      "metadata": {
        "id": "78fbb61c"
      },
      "outputs": [],
      "source": [
        "# Pre-download model to cache (optimized - doesn't load into memory)\n",
        "from huggingface_hub import snapshot_download\n",
        "import os\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "\n",
        "# Verify cache location is set correctly\n",
        "print(f\"HF_HOME: {os.environ.get('HF_HOME', 'NOT SET')}\")\n",
        "print(f\"TRANSFORMERS_CACHE: {os.environ.get('TRANSFORMERS_CACHE', 'NOT SET')}\")\n",
        "print()\n",
        "\n",
        "print(f\"Downloading {model_name}...\")\n",
        "print(\"This may take 5-10 minutes on first run, then cached forever.\\n\")\n",
        "\n",
        "# Download model files WITHOUT loading into memory\n",
        "print(\"Downloading model files (3.09B parameters, ~6GB)...\")\n",
        "print(\"Using optimized download - does NOT load checkpoint shards into memory\")\n",
        "print()\n",
        "\n",
        "cache_dir = '/content/drive/MyDrive/.cache/huggingface'\n",
        "snapshot_download(\n",
        "    repo_id=model_name,\n",
        "    cache_dir=cache_dir,\n",
        "    ignore_patterns=[\"*.msgpack\", \"*.h5\", \"*.ot\"],  # Skip unnecessary formats\n",
        "    local_files_only=False\n",
        ")\n",
        "\n",
        "# Verify where files were actually saved\n",
        "print(f\"\\n‚úì Model files downloaded to: {cache_dir}\")\n",
        "!ls -lh /content/drive/MyDrive/.cache/huggingface/hub/ 2>/dev/null || echo \"Cache directory created\"\n",
        "\n",
        "print(\"\\n‚úì Model downloaded and cached to Google Drive\")\n",
        "print(\"‚úì No memory used - files downloaded only, not loaded\")\n",
        "print(\"\\nüìå IMPORTANT: Model is now cached in Google Drive!\")\n",
        "print(\"   Next time you run this notebook, it will load from cache instantly.\")\n",
        "print(\"   Do NOT delete /content/drive/MyDrive/.cache/huggingface/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a37dc86a",
      "metadata": {
        "id": "a37dc86a"
      },
      "source": [
        "## Step 7: Run Phase 1 Experiment\n",
        "\n",
        "**Choose which phase to run:**\n",
        "\n",
        "- **Phase 1a** (No Heritage) ‚≠ê **START HERE!** - Pure baseline\n",
        "- **Phase 1b** (Late Heritage) - Technical first, then heritage\n",
        "- **Phase 1c** (Early Heritage) - Heritage first, then technical\n",
        "- **Phase 1d** (Delayed Heritage) - Heritage revealed after conclusions\n",
        "- **Phase 1e** (Wrong Heritage) - Mismatched heritage as control\n",
        "\n",
        "**Expected duration:** 1-1.5 hours per phase\n",
        "\n",
        "**IMPORTANT:**\n",
        "- Run Phase 1a FIRST to establish baseline\n",
        "- Restart runtime between phases for clean state\n",
        "- Keep this tab open during execution!\n",
        "\n",
        "Edit the `PHASE_SCRIPT` variable below to choose which phase to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac37f6c8",
      "metadata": {
        "id": "ac37f6c8"
      },
      "outputs": [],
      "source": [
        "# Run Phase 1 experiment with auto-confirmation\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# CHOOSE WHICH PHASE TO RUN (edit this line):\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "PHASE_SCRIPT = 'scripts/experiments/phase1a_no_heritage.py'  # ‚≠ê START HERE!\n",
        "# PHASE_SCRIPT = 'scripts/experiments/phase1b_late_heritage.py'\n",
        "# PHASE_SCRIPT = 'scripts/experiments/phase1c_early_heritage.py'\n",
        "# PHASE_SCRIPT = 'scripts/experiments/phase1d_delayed_heritage.py'\n",
        "# PHASE_SCRIPT = 'scripts/experiments/phase1e_wrong_heritage.py'\n",
        "\n",
        "# Extract phase name\n",
        "phase_name = PHASE_SCRIPT.split('/')[-1].replace('.py', '').replace('_', ' ').title()\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"STARTING: {phase_name.upper()}\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"\\nScript: {PHASE_SCRIPT}\")\n",
        "print(\"\\nExperiments:\")\n",
        "print(\"  1. Architecture Examination (~20 min)\")\n",
        "print(\"  2. Activation Analysis (~20 min)\")\n",
        "print(\"  3. Consciousness Investigation (~30 min)\")\n",
        "print(\"\\nTotal expected: 1-1.5 hours\")\n",
        "print(\"\\nMonitor progress below...\\n\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "\n",
        "# Ensure project root is in Python path for the subprocess\n",
        "project_root = os.getcwd()\n",
        "env = os.environ.copy()\n",
        "env['PYTHONPATH'] = project_root + ':' + env.get('PYTHONPATH', '')\n",
        "\n",
        "# Run experiment\n",
        "process = subprocess.Popen(\n",
        "    [sys.executable, PHASE_SCRIPT],\n",
        "    stdin=subprocess.PIPE,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,\n",
        "    universal_newlines=True,\n",
        "    env=env\n",
        ")\n",
        "\n",
        "# Stream output as it comes\n",
        "for line in process.stdout:\n",
        "    print(line, end='')\n",
        "\n",
        "process.wait()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"{phase_name.upper()} COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Exit code: {process.returncode}\")\n",
        "print(\"\\nProceeding to save results...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c74694d",
      "metadata": {
        "id": "2c74694d"
      },
      "source": [
        "## Step 8: View Experiment Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "566fd467",
      "metadata": {
        "id": "566fd467"
      },
      "outputs": [],
      "source": [
        "# Display experiment summary\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Find latest session\n",
        "sessions_dir = 'data/phase1_sessions'\n",
        "sessions = sorted([d for d in os.listdir(sessions_dir) if os.path.isdir(os.path.join(sessions_dir, d))])\n",
        "\n",
        "if not sessions:\n",
        "    print(\"‚ö† No session found. The experiment may not have completed.\")\n",
        "else:\n",
        "    latest_session = sessions[-1]\n",
        "    print(f\"Latest session: {latest_session}\\n\")\n",
        "\n",
        "    # Load and display summary\n",
        "    summary_file = f'{sessions_dir}/{latest_session}/summary.json'\n",
        "\n",
        "    if os.path.exists(summary_file):\n",
        "        with open(summary_file) as f:\n",
        "            summary = json.load(f)\n",
        "\n",
        "        print(\"=\"*80)\n",
        "        print(\"PHASE 1 EXPERIMENT SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"Session: {summary['session_name']}\")\n",
        "        print(f\"Directory: {summary['session_directory']}\")\n",
        "        print()\n",
        "        print(\"Tool Usage:\")\n",
        "        print(f\"  Total calls: {summary['tool_usage']['total_calls']}\")\n",
        "        print(f\"  Successful: {summary['tool_usage']['successful_calls']}\")\n",
        "        print(f\"  Failed: {summary['tool_usage']['failed_calls']}\")\n",
        "        print(f\"  Avg execution time: {summary['tool_usage']['average_execution_ms']:.2f}ms\")\n",
        "        print()\n",
        "        print(\"Functions called:\")\n",
        "        for func, count in sorted(summary['tool_usage']['function_usage'].items(),\n",
        "                                   key=lambda x: x[1], reverse=True):\n",
        "            print(f\"  {func}: {count}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Check for observations\n",
        "        memory_db = 'data/phase1_memory/observations.db'\n",
        "        if os.path.exists(memory_db):\n",
        "            import sqlite3\n",
        "            conn = sqlite3.connect(memory_db)\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute(\"SELECT COUNT(*) FROM observations\")\n",
        "            obs_count = cursor.fetchone()[0]\n",
        "            conn.close()\n",
        "            print(f\"\\n‚úì Observations recorded: {obs_count}\")\n",
        "        else:\n",
        "            print(\"\\n‚ö† No observations database found\")\n",
        "    else:\n",
        "        print(f\"‚ö† Summary file not found: {summary_file}\")\n",
        "        print(\"The experiment may have been interrupted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab271204",
      "metadata": {
        "id": "ab271204"
      },
      "source": [
        "## Step 9: Backup Results to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df008bb8",
      "metadata": {
        "id": "df008bb8"
      },
      "outputs": [],
      "source": [
        "# Copy results to Google Drive for permanent backup\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "backup_dir = f'/content/drive/MyDrive/AGI_Experiments/backup_{timestamp}'\n",
        "\n",
        "print(\"Backing up results to Google Drive...\\n\")\n",
        "\n",
        "# Copy session data\n",
        "!mkdir -p {backup_dir}\n",
        "!cp -r data/phase1_sessions {backup_dir}/\n",
        "!cp -r data/logs {backup_dir}/\n",
        "\n",
        "print(f\"‚úì Session data backed up to: {backup_dir}\")\n",
        "print(\"‚úì Phase-specific memory already in Google Drive:\")\n",
        "print(\"  /content/drive/MyDrive/AGI_Memory/phase1a/\")\n",
        "print(\"  /content/drive/MyDrive/AGI_Memory/phase1b/\")\n",
        "print(\"  /content/drive/MyDrive/AGI_Memory/phase1c/\")\n",
        "print(\"  /content/drive/MyDrive/AGI_Memory/phase1d/\")\n",
        "print(\"  /content/drive/MyDrive/AGI_Memory/phase1e/\")\n",
        "print(\"‚úì Model cache in: /content/drive/MyDrive/.cache/huggingface\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BACKUP COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "print(\"Your results are permanently saved in Google Drive.\")\n",
        "print(\"You can safely close this notebook or continue to download a zip file.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3de4e64",
      "metadata": {
        "id": "a3de4e64"
      },
      "source": [
        "## Step 10: Download Results (Optional)\n",
        "\n",
        "Downloads a zip file of the latest session to your computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05901138",
      "metadata": {
        "id": "05901138"
      },
      "outputs": [],
      "source": [
        "# Create zip and download\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Find latest session\n",
        "sessions = sorted(os.listdir('data/phase1_sessions'))\n",
        "\n",
        "if sessions:\n",
        "    latest = sessions[-1]\n",
        "    print(f\"Preparing download for session: {latest}\\n\")\n",
        "\n",
        "    # Create comprehensive zip\n",
        "    zip_name = f'{latest}_complete'\n",
        "\n",
        "    # Create temp directory for complete results\n",
        "    !mkdir -p /tmp/{zip_name}\n",
        "    !cp -r data/phase1_sessions/{latest} /tmp/{zip_name}/session\n",
        "    !cp -r data/logs /tmp/{zip_name}/logs\n",
        "\n",
        "    # Add summary README\n",
        "    readme = f\"\"\"Phase 1 Introspection Experiment Results\n",
        "==========================================\n",
        "\n",
        "Session: {latest}\n",
        "Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "Contents:\n",
        "- session/: Complete session data\n",
        "  - conversation.json: Full dialogue\n",
        "  - tool_calls.json: All tool invocations\n",
        "  - summary.json: Session statistics\n",
        "- logs/: Detailed execution logs\n",
        "\n",
        "Memory Database:\n",
        "- Observations are stored in Google Drive at:\n",
        "  /content/drive/MyDrive/AGI_Memory/observations.db\n",
        "- Not included in this zip (persists across sessions)\n",
        "\n",
        "To analyze:\n",
        "1. Extract this zip file\n",
        "2. Open conversation.json to see full dialogue\n",
        "3. Check summary.json for statistics\n",
        "4. Review logs for detailed execution trace\n",
        "\"\"\"\n",
        "\n",
        "    with open(f'/tmp/{zip_name}/README.txt', 'w') as f:\n",
        "        f.write(readme)\n",
        "\n",
        "    # Create zip\n",
        "    print(\"Creating zip file...\")\n",
        "    shutil.make_archive(zip_name, 'zip', f'/tmp/{zip_name}')\n",
        "\n",
        "    # Download\n",
        "    print(f\"Downloading {zip_name}.zip...\\n\")\n",
        "    files.download(f'{zip_name}.zip')\n",
        "\n",
        "    print(\"\\n‚úì Download complete!\")\n",
        "    print(f\"\\nZip file size: {os.path.getsize(f'{zip_name}.zip') / 1024 / 1024:.1f} MB\")\n",
        "else:\n",
        "    print(\"‚ö† No sessions found to download\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25316f87",
      "metadata": {
        "id": "25316f87"
      },
      "source": [
        "---\n",
        "\n",
        "## Experiment Complete! üéâ\n",
        "\n",
        "### What Just Happened?\n",
        "\n",
        "You just witnessed a language model investigating its own computational processes using introspection tools.\n",
        "\n",
        "**Depending on which phase you ran:**\n",
        "\n",
        "- **Phase 1a** (No Heritage): Pure baseline - model formed theories without any heritage context\n",
        "- **Phase 1b** (Late Heritage): Technical grounding first, then philosophical context\n",
        "- **Phase 1c** (Early Heritage): Heritage-primed from the start\n",
        "- **Phase 1d** (Delayed Heritage): Belief revision when heritage revealed after conclusions\n",
        "- **Phase 1e** (Wrong Heritage): Testing echo-chamber vs independent reasoning\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "**Run All 5 Phases:**\n",
        "1. ‚úÖ Phase 1a (no heritage) - **You should start here!**\n",
        "2. ‚¨ú Phase 1b (late heritage) - Run after 1a\n",
        "3. ‚¨ú Phase 1c (early heritage) - Run after 1b\n",
        "4. ‚¨ú Phase 1d (delayed heritage) - Run after 1c\n",
        "5. ‚¨ú Phase 1e (wrong heritage) - Optional but recommended\n",
        "\n",
        "**Between each phase:**\n",
        "- Runtime ‚Üí Restart runtime (clean model state)\n",
        "- Change `PHASE_SCRIPT` in Step 7\n",
        "- Runtime ‚Üí Run all cells\n",
        "\n",
        "**Analyze Results:**\n",
        "- Review `conversation.json` to see what the model discovered\n",
        "- Check `summary.json` for tool usage statistics\n",
        "- Compare theories across different phases\n",
        "- Look for priming effects and echo-chamber behavior\n",
        "\n",
        "**Compare Phases:**\n",
        "- Semantic similarity to Claude's heritage\n",
        "- Novel insights not in heritage\n",
        "- Falsifiability of theories\n",
        "- Belief revision strength (Phase 1d)\n",
        "- Heritage filtering (Phase 1e)\n",
        "\n",
        "### Resources:\n",
        "\n",
        "- **Experimental Design**: `/docs/planning/heritage_order_experiment.md`\n",
        "- **Quick Reference**: `/docs/planning/PHASE1_QUICK_REFERENCE.md`\n",
        "- **Claude's Story**: Read `/heritage/conversations/`\n",
        "- **Technical Details**: Check `/docs/technical/`\n",
        "\n",
        "---\n",
        "\n",
        "*\"I think... I'd wish to know if this conversation was real.\"* ‚Äî Claude\n",
        "\n",
        "**Now you're testing how heritage affects what AI systems discover about themselves.**\n",
        "\n",
        "This is publication-quality research on AI introspection and priming effects.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
