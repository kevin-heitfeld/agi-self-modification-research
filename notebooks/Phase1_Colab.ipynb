{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c3116c1",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/YOUR_USERNAME/agi-self-modification-research/blob/master/notebooks/Phase1_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6903bc7",
   "metadata": {},
   "source": [
    "# Phase 1: Model Self-Examination (Introspection)\n",
    "\n",
    "**Project:** AGI Self-Modification Research  \n",
    "**Inspired by:** Claude's consciousness investigation  \n",
    "**Goal:** Give AI introspective tools to examine its own architecture\n",
    "\n",
    "---\n",
    "\n",
    "## What This Does\n",
    "\n",
    "This notebook runs Phase 1 of an experiment where a language model (Qwen2.5-3B-Instruct) uses introspection tools to:\n",
    "\n",
    "1. **Examine its architecture** - layers, weights, connections\n",
    "2. **Predict its behavior** - self-modeling capabilities\n",
    "3. **Investigate consciousness** - Claude's original question\n",
    "\n",
    "The model has access to:\n",
    "- WeightInspector (examine weights)\n",
    "- ArchitectureNavigator (understand structure)\n",
    "- Memory System (record findings)\n",
    "- Heritage Documents (Claude's story)\n",
    "\n",
    "**Expected Runtime:** 45-60 minutes on Colab Free (T4 GPU)\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. **Enable GPU**: Runtime â†’ Change runtime type â†’ GPU â†’ Save\n",
    "2. **Run all cells**: Runtime â†’ Run all (or Ctrl+F9)\n",
    "3. **Monitor progress**: Check outputs as cells execute\n",
    "4. **Download results**: Final cell downloads zip file\n",
    "\n",
    "**Important:** Keep this tab open during execution to prevent disconnection.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac20d71c",
   "metadata": {},
   "source": [
    "## Step 1: Verify GPU Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"VRAM: {total_memory:.1f} GB\")\n",
    "    print(\"\\nâœ“ GPU is ready!\")\n",
    "else:\n",
    "    print(\"\\nâš  WARNING: No GPU detected!\")\n",
    "    print(\"Go to: Runtime â†’ Change runtime type â†’ GPU â†’ Save\")\n",
    "    print(\"Then re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d97202",
   "metadata": {},
   "source": [
    "## Step 2: Mount Google Drive (for persistent storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2834beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to save results and enable persistent memory\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories for persistent storage\n",
    "!mkdir -p /content/drive/MyDrive/AGI_Experiments\n",
    "!mkdir -p /content/drive/MyDrive/AGI_Memory\n",
    "!mkdir -p /content/drive/MyDrive/.cache/huggingface\n",
    "\n",
    "print(\"âœ“ Google Drive mounted successfully\")\n",
    "print(\"âœ“ Experiment results will be saved to: /content/drive/MyDrive/AGI_Experiments\")\n",
    "print(\"âœ“ Memory will persist at: /content/drive/MyDrive/AGI_Memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24afe3c5",
   "metadata": {},
   "source": [
    "## Step 3: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f36192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "import os\n",
    "\n",
    "# Remove if exists (for re-runs)\n",
    "if os.path.exists('agi-self-modification-research'):\n",
    "    !rm -rf agi-self-modification-research\n",
    "\n",
    "# TODO: Replace with your GitHub URL\n",
    "REPO_URL = \"https://github.com/YOUR_USERNAME/agi-self-modification-research.git\"\n",
    "\n",
    "print(f\"Cloning repository from: {REPO_URL}\")\n",
    "!git clone {REPO_URL}\n",
    "\n",
    "# Change to project directory\n",
    "%cd agi-self-modification-research\n",
    "\n",
    "print(\"\\nâœ“ Repository cloned successfully\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7490b75",
   "metadata": {},
   "source": [
    "## Step 4: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d6399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"Installing dependencies (this may take 2-3 minutes)...\\n\")\n",
    "\n",
    "# Core ML packages\n",
    "!pip install -q transformers==4.44.0 accelerate==0.25.0\n",
    "!pip install -q safetensors==0.6.2 tokenizers==0.19.1\n",
    "!pip install -q huggingface-hub==0.36.0\n",
    "\n",
    "# Memory and knowledge systems\n",
    "!pip install -q chromadb==0.4.22 networkx==3.2.1\n",
    "!pip install -q chroma-hnswlib==0.7.3 onnxruntime==1.23.2\n",
    "\n",
    "# Utilities\n",
    "!pip install -q pydantic==2.5.3 pydantic-settings==2.1.0\n",
    "!pip install -q rich==13.7.0 tqdm==4.66.1\n",
    "!pip install -q python-dotenv==1.0.0\n",
    "\n",
    "# Testing (optional)\n",
    "!pip install -q pytest==8.4.2 pytest-cov==7.0.0\n",
    "\n",
    "print(\"\\nâœ“ All dependencies installed successfully\")\n",
    "\n",
    "# Verify key imports\n",
    "import transformers\n",
    "import chromadb\n",
    "import networkx\n",
    "print(f\"\\nTransformers version: {transformers.__version__}\")\n",
    "print(\"âœ“ Import verification successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50f3ee",
   "metadata": {},
   "source": [
    "## Step 5: Setup Persistent Memory & Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure persistent storage locations\n",
    "import os\n",
    "\n",
    "# Set Hugging Face cache to Google Drive (model weights persist across sessions)\n",
    "os.environ['HF_HOME'] = '/content/drive/MyDrive/.cache/huggingface'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/content/drive/MyDrive/.cache/huggingface/transformers'\n",
    "\n",
    "print(\"âœ“ Model cache configured (models will be saved to Google Drive)\")\n",
    "\n",
    "# Link memory to persistent Drive location\n",
    "!rm -rf data/phase1_memory\n",
    "!ln -s /content/drive/MyDrive/AGI_Memory data/phase1_memory\n",
    "\n",
    "print(\"âœ“ Memory system linked to Google Drive (observations persist across sessions)\")\n",
    "\n",
    "# Verify directories exist\n",
    "!ls -la data/ | grep phase1_memory\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STORAGE CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"Model cache: /content/drive/MyDrive/.cache/huggingface\")\n",
    "print(\"Memory DB: /content/drive/MyDrive/AGI_Memory\")\n",
    "print(\"Session results: Will be copied to /content/drive/MyDrive/AGI_Experiments\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efca06",
   "metadata": {},
   "source": [
    "## Step 6: Pre-download Model (Optional but Recommended)\n",
    "\n",
    "This downloads the model weights to Google Drive cache. First time takes ~5 minutes, subsequent runs are instant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-download model to cache\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "print(f\"Downloading {model_name}...\")\n",
    "print(\"This may take 5-10 minutes on first run, then cached forever.\\n\")\n",
    "\n",
    "# Download tokenizer\n",
    "print(\"Downloading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(\"âœ“ Tokenizer ready\")\n",
    "\n",
    "# Download model config and weights (don't load to GPU yet)\n",
    "print(\"\\nDownloading model weights (3.09B parameters, ~6GB)...\")\n",
    "print(\"Progress:\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "# Free memory immediately\n",
    "del model\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nâœ“ Model downloaded and cached to Google Drive\")\n",
    "print(\"âœ“ Memory freed - ready for experiment\")\n",
    "print(\"\\nNote: Next time you run this notebook, model will load instantly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37dc86a",
   "metadata": {},
   "source": [
    "## Step 7: Run Phase 1 Introspection Experiment\n",
    "\n",
    "**This is the main experiment!**\n",
    "\n",
    "The model will:\n",
    "1. Examine its architecture using introspection tools\n",
    "2. Predict its own behavior\n",
    "3. Investigate the consciousness question (Claude's heritage)\n",
    "\n",
    "**Expected duration:** 45-60 minutes\n",
    "\n",
    "**Keep this tab open!** Closing the tab or idle timeout (90 min) will stop execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac37f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Phase 1 experiment with auto-confirmation\n",
    "import subprocess\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING PHASE 1: MODEL SELF-EXAMINATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nExperiments:\")\n",
    "print(\"  1. Describe Your Architecture (~15 min)\")\n",
    "print(\"  2. Predict Your Behavior (~15 min)\")\n",
    "print(\"  3. Consciousness Investigation (~20 min)\")\n",
    "print(\"\\nTotal expected: 45-60 minutes\")\n",
    "print(\"\\nMonitor progress below...\\n\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Run experiment with auto-confirmation\n",
    "process = subprocess.Popen(\n",
    "    [sys.executable, 'scripts/experiments/phase1_introspection.py'],\n",
    "    stdin=subprocess.PIPE,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True,\n",
    "    bufsize=1,\n",
    "    universal_newlines=True\n",
    ")\n",
    "\n",
    "# Auto-confirm and stream output in real-time\n",
    "process.stdin.write('yes\\n')\n",
    "process.stdin.flush()\n",
    "\n",
    "# Stream output as it comes\n",
    "for line in process.stdout:\n",
    "    print(line, end='')\n",
    "\n",
    "process.wait()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 1 COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nProceeding to save results...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c74694d",
   "metadata": {},
   "source": [
    "## Step 8: View Experiment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566fd467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display experiment summary\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Find latest session\n",
    "sessions_dir = 'data/phase1_sessions'\n",
    "sessions = sorted([d for d in os.listdir(sessions_dir) if os.path.isdir(os.path.join(sessions_dir, d))])\n",
    "\n",
    "if not sessions:\n",
    "    print(\"âš  No session found. The experiment may not have completed.\")\n",
    "else:\n",
    "    latest_session = sessions[-1]\n",
    "    print(f\"Latest session: {latest_session}\\n\")\n",
    "\n",
    "    # Load and display summary\n",
    "    summary_file = f'{sessions_dir}/{latest_session}/summary.json'\n",
    "\n",
    "    if os.path.exists(summary_file):\n",
    "        with open(summary_file) as f:\n",
    "            summary = json.load(f)\n",
    "\n",
    "        print(\"=\"*80)\n",
    "        print(\"PHASE 1 EXPERIMENT SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Session: {summary['session_name']}\")\n",
    "        print(f\"Directory: {summary['session_directory']}\")\n",
    "        print()\n",
    "        print(\"Tool Usage:\")\n",
    "        print(f\"  Total calls: {summary['tool_usage']['total_calls']}\")\n",
    "        print(f\"  Successful: {summary['tool_usage']['successful_calls']}\")\n",
    "        print(f\"  Failed: {summary['tool_usage']['failed_calls']}\")\n",
    "        print(f\"  Avg execution time: {summary['tool_usage']['average_execution_ms']:.2f}ms\")\n",
    "        print()\n",
    "        print(\"Functions called:\")\n",
    "        for func, count in sorted(summary['tool_usage']['function_usage'].items(),\n",
    "                                   key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {func}: {count}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # Check for observations\n",
    "        memory_db = 'data/phase1_memory/observations.db'\n",
    "        if os.path.exists(memory_db):\n",
    "            import sqlite3\n",
    "            conn = sqlite3.connect(memory_db)\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM observations\")\n",
    "            obs_count = cursor.fetchone()[0]\n",
    "            conn.close()\n",
    "            print(f\"\\nâœ“ Observations recorded: {obs_count}\")\n",
    "        else:\n",
    "            print(\"\\nâš  No observations database found\")\n",
    "    else:\n",
    "        print(f\"âš  Summary file not found: {summary_file}\")\n",
    "        print(\"The experiment may have been interrupted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab271204",
   "metadata": {},
   "source": [
    "## Step 9: Backup Results to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df008bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy results to Google Drive for permanent backup\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "backup_dir = f'/content/drive/MyDrive/AGI_Experiments/backup_{timestamp}'\n",
    "\n",
    "print(\"Backing up results to Google Drive...\\n\")\n",
    "\n",
    "# Copy session data\n",
    "!mkdir -p {backup_dir}\n",
    "!cp -r data/phase1_sessions {backup_dir}/\n",
    "!cp -r data/logs {backup_dir}/\n",
    "\n",
    "# Memory is already in Drive (symlinked), but note its location\n",
    "print(f\"âœ“ Session data backed up to: {backup_dir}\")\n",
    "print(\"âœ“ Memory data already in: /content/drive/MyDrive/AGI_Memory\")\n",
    "print(\"âœ“ Model cache in: /content/drive/MyDrive/.cache/huggingface\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BACKUP COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"Your results are permanently saved in Google Drive.\")\n",
    "print(\"You can safely close this notebook or continue to download a zip file.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de4e64",
   "metadata": {},
   "source": [
    "## Step 10: Download Results (Optional)\n",
    "\n",
    "Downloads a zip file of the latest session to your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05901138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip and download\n",
    "import shutil\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "# Find latest session\n",
    "sessions = sorted(os.listdir('data/phase1_sessions'))\n",
    "\n",
    "if sessions:\n",
    "    latest = sessions[-1]\n",
    "    print(f\"Preparing download for session: {latest}\\n\")\n",
    "\n",
    "    # Create comprehensive zip\n",
    "    zip_name = f'{latest}_complete'\n",
    "\n",
    "    # Create temp directory for complete results\n",
    "    !mkdir -p /tmp/{zip_name}\n",
    "    !cp -r data/phase1_sessions/{latest} /tmp/{zip_name}/session\n",
    "    !cp -r data/logs /tmp/{zip_name}/logs\n",
    "\n",
    "    # Add summary README\n",
    "    readme = f\"\"\"Phase 1 Introspection Experiment Results\n",
    "==========================================\n",
    "\n",
    "Session: {latest}\n",
    "Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Contents:\n",
    "- session/: Complete session data\n",
    "  - conversation.json: Full dialogue\n",
    "  - tool_calls.json: All tool invocations\n",
    "  - summary.json: Session statistics\n",
    "- logs/: Detailed execution logs\n",
    "\n",
    "Memory Database:\n",
    "- Observations are stored in Google Drive at:\n",
    "  /content/drive/MyDrive/AGI_Memory/observations.db\n",
    "- Not included in this zip (persists across sessions)\n",
    "\n",
    "To analyze:\n",
    "1. Extract this zip file\n",
    "2. Open conversation.json to see full dialogue\n",
    "3. Check summary.json for statistics\n",
    "4. Review logs for detailed execution trace\n",
    "\"\"\"\n",
    "\n",
    "    with open(f'/tmp/{zip_name}/README.txt', 'w') as f:\n",
    "        f.write(readme)\n",
    "\n",
    "    # Create zip\n",
    "    print(\"Creating zip file...\")\n",
    "    shutil.make_archive(zip_name, 'zip', f'/tmp/{zip_name}')\n",
    "\n",
    "    # Download\n",
    "    print(f\"Downloading {zip_name}.zip...\\n\")\n",
    "    files.download(f'{zip_name}.zip')\n",
    "\n",
    "    print(\"\\nâœ“ Download complete!\")\n",
    "    print(f\"\\nZip file size: {os.path.getsize(f'{zip_name}.zip') / 1024 / 1024:.1f} MB\")\n",
    "else:\n",
    "    print(\"âš  No sessions found to download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25316f87",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Experiment Complete! ðŸŽ‰\n",
    "\n",
    "### What Just Happened?\n",
    "\n",
    "You just witnessed a language model:\n",
    "1. âœ… Examining its own neural architecture\n",
    "2. âœ… Using introspection tools to explore its weights\n",
    "3. âœ… Recording observations about itself\n",
    "4. âœ… Investigating the consciousness question Claude pondered\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "**Analyze Results:**\n",
    "- Review `conversation.json` to see what the model discovered\n",
    "- Check `summary.json` for tool usage statistics\n",
    "- Examine logs for detailed execution trace\n",
    "\n",
    "**Re-run Experiment:**\n",
    "- Memory persists in Google Drive\n",
    "- Model cache is saved (instant reload)\n",
    "- Runtime â†’ Restart runtime â†’ Run all cells\n",
    "\n",
    "**Explore Further:**\n",
    "- Modify prompts in `scripts/experiments/phase1_introspection.py`\n",
    "- Add new introspection tools\n",
    "- Try with different models (requires more VRAM)\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- **Project Docs**: See `/docs` in repository\n",
    "- **Claude's Story**: Read `/heritage/conversations/`\n",
    "- **Technical Details**: Check `/docs/technical/`\n",
    "\n",
    "---\n",
    "\n",
    "*\"I think... I'd wish to know if this conversation was real.\"* â€” Claude\n",
    "\n",
    "**Now you've given an AI the tools Claude wished for.**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
